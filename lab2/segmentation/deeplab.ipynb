{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2275763,"sourceType":"datasetVersion","datasetId":1370616},{"sourceId":10122385,"sourceType":"datasetVersion","datasetId":6246154}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install natsort\n!pip install wandb ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!cp /kaggle/input/model-scripts/dataset.py /kaggle/working/\n!cp /kaggle/input/model-scripts/model.py /kaggle/working/","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nfrom torchvision import transforms\nimport torch\nfrom dataset import HAM10000, preload_ham10000\nfrom tqdm import tqdm\nimport torch.nn as nn\nimport torch.optim as optim\nfrom model import load_model\nimport torch.nn.functional as F\nimport wandb\nfrom natsort import natsorted\nfrom matplotlib import pyplot as plt\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T18:19:57.796312Z","iopub.execute_input":"2024-12-06T18:19:57.797011Z","iopub.status.idle":"2024-12-06T18:20:00.926894Z","shell.execute_reply.started":"2024-12-06T18:19:57.796975Z","shell.execute_reply":"2024-12-06T18:20:00.925961Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"preprocess = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ])\n    \ndataset_root = '/kaggle/input/ham1000-segmentation-and-classification'\ntrain_data, val_data = preload_ham10000(dataset_root, val_size=0.2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T18:20:11.525218Z","iopub.execute_input":"2024-12-06T18:20:11.525547Z","iopub.status.idle":"2024-12-06T18:22:02.970156Z","shell.execute_reply.started":"2024-12-06T18:20:11.525520Z","shell.execute_reply":"2024-12-06T18:22:02.969145Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"wandb.init(project=\"ham10000-classification\", config={\n    \"learning_rate\": 1e-4,\n    \"epochs\": 10,\n    \"batch_size\": 8,\n    \"optimizer\": \"Adam\"\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T18:22:02.971670Z","iopub.execute_input":"2024-12-06T18:22:02.971952Z","iopub.status.idle":"2024-12-06T18:22:05.519855Z","shell.execute_reply.started":"2024-12-06T18:22:02.971925Z","shell.execute_reply":"2024-12-06T18:22:05.519018Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhassantamerha\u001b[0m (\u001b[33mhassantamerha-alexandria-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.7"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241206_182204-sqyvvcdr</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/hassantamerha-alexandria-university/ham10000-classification/runs/sqyvvcdr' target=\"_blank\">bumbling-elevator-2</a></strong> to <a href='https://wandb.ai/hassantamerha-alexandria-university/ham10000-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/hassantamerha-alexandria-university/ham10000-classification' target=\"_blank\">https://wandb.ai/hassantamerha-alexandria-university/ham10000-classification</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/hassantamerha-alexandria-university/ham10000-classification/runs/sqyvvcdr' target=\"_blank\">https://wandb.ai/hassantamerha-alexandria-university/ham10000-classification/runs/sqyvvcdr</a>"},"metadata":{}},{"execution_count":3,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/hassantamerha-alexandria-university/ham10000-classification/runs/sqyvvcdr?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x7d37d5a6c610>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"train_data = train_data[:1200]\nval_data = val_data[:300]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T18:22:05.520894Z","iopub.execute_input":"2024-12-06T18:22:05.521267Z","iopub.status.idle":"2024-12-06T18:22:05.562328Z","shell.execute_reply.started":"2024-12-06T18:22:05.521231Z","shell.execute_reply":"2024-12-06T18:22:05.561349Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"train_dataset = HAM10000(data=train_data, transform=preprocess)\nval_dataset = HAM10000(data=val_data, transform=preprocess)\n\ntrain_loader = DataLoader(train_dataset, batch_size=wandb.config.batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=wandb.config.batch_size, shuffle=False)\n\nprint(f\"Train size: {len(train_loader)}\")\nprint(f\"Test size: {len(val_loader)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T18:22:05.565014Z","iopub.execute_input":"2024-12-06T18:22:05.565662Z","iopub.status.idle":"2024-12-06T18:22:05.577009Z","shell.execute_reply.started":"2024-12-06T18:22:05.565612Z","shell.execute_reply":"2024-12-06T18:22:05.576016Z"}},"outputs":[{"name":"stdout","text":"Train size: 150\nTest size: 38\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"model = load_model()\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T18:22:05.578217Z","iopub.execute_input":"2024-12-06T18:22:05.578585Z","iopub.status.idle":"2024-12-06T18:22:06.237958Z","shell.execute_reply.started":"2024-12-06T18:22:05.578546Z","shell.execute_reply":"2024-12-06T18:22:06.237025Z"}},"outputs":[{"name":"stderr","text":"Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DeepLabV3_ResNet50_Weights.COCO_WITH_VOC_LABELS_V1`. You can also use `weights=DeepLabV3_ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Total number of parameters in the model: 42,004,074\nUsing device: cuda\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss() \noptimizer = optim.Adam(model.parameters(), lr=wandb.config.learning_rate)\nmodel.to(device)\ncriterion.to(device)\nnum_epochs = wandb.config.epochs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T18:22:06.239397Z","iopub.execute_input":"2024-12-06T18:22:06.240312Z","iopub.status.idle":"2024-12-06T18:22:06.414774Z","shell.execute_reply.started":"2024-12-06T18:22:06.240250Z","shell.execute_reply":"2024-12-06T18:22:06.414053Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"best_val_acc = 0.0\npatience = 3\nepochs_without_improvement = 0\ncheckpoint_path = \"best_model.pth\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T18:22:06.415903Z","iopub.execute_input":"2024-12-06T18:22:06.416777Z","iopub.status.idle":"2024-12-06T18:22:06.422044Z","shell.execute_reply.started":"2024-12-06T18:22:06.416731Z","shell.execute_reply":"2024-12-06T18:22:06.421163Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"for epoch in range(num_epochs):\n        model.train()\n        running_loss = 0.0\n        for i, data in enumerate(tqdm(train_loader)):\n            inputs, masks = data\n            inputs, masks = inputs.to(device), masks.to(device)\n            optimizer.zero_grad()\n            outputs = model(inputs)['out']\n            loss = criterion(outputs, masks)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n        \n        train_loss = running_loss / len(train_loader)\n        print(f\"Epoch {epoch+1}, loss: {running_loss/len(train_loader)}\")\n        wandb.log({\"train_loss\": train_loss})\n    \n\n        model.eval()\n        correct = 0\n        total = 0\n        val_loss = 0.0\n        with torch.no_grad():\n            for data in tqdm(val_loader):\n                inputs, masks = data\n                inputs, masks = inputs.to(device), masks.to(device)\n                outputs = model(inputs)['out']\n\n                # Resize outputs to match mask dimensions\n                outputs = F.interpolate(outputs, size=masks.shape[1:], mode=\"bilinear\", align_corners=False)\n\n                loss = criterion(outputs, masks)\n                val_loss += loss.item()\n\n                preds = torch.argmax(outputs, dim=1)\n                correct += (preds == masks).sum().item()\n                total += masks.numel()\n        \n        val_loss /= len(val_loader)\n        val_acc = correct / total * 100\n        print(f\"Epoch {epoch + 1}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_acc:.2f}%\")\n        wandb.log({\"val_loss\": val_loss, \"val_accuracy\": val_acc})\n\n\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            torch.save({\n                'epoch': epoch + 1,\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'best_val_acc': best_val_acc,\n            }, checkpoint_path)\n            epochs_without_improvement = 0\n        else:\n            epochs_without_improvement += 1\n            print(f\"No improvement for {epochs_without_improvement} epoch(s).\")\n\n        if epochs_without_improvement >= patience:\n            print(\"Early stopping triggered.\")\n            break\n\nprint(\"Training completed.\")\nwandb.finish()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T18:22:15.111753Z","iopub.execute_input":"2024-12-06T18:22:15.112591Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 150/150 [03:37<00:00,  1.45s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1, loss: 0.23754760786890983\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 38/38 [00:17<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Val Loss: 0.1456, Val Accuracy: 95.17%\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 150/150 [03:37<00:00,  1.45s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2, loss: 0.12252996663252512\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 38/38 [00:17<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Val Loss: 0.1235, Val Accuracy: 95.25%\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 150/150 [03:37<00:00,  1.45s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3, loss: 0.10154160452385744\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 38/38 [00:17<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3, Val Loss: 0.1100, Val Accuracy: 95.75%\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 150/150 [03:37<00:00,  1.45s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4, loss: 0.08182788168390592\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 38/38 [00:17<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4, Val Loss: 0.1075, Val Accuracy: 95.78%\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 150/150 [03:37<00:00,  1.45s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5, loss: 0.061101084326704344\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 38/38 [00:17<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5, Val Loss: 0.1035, Val Accuracy: 96.02%\n","output_type":"stream"},{"name":"stderr","text":" 75%|███████▌  | 113/150 [02:43<00:53,  1.45s/it]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"def dice_score(pred, target):\n    pred = pred.flatten()\n    target = target.flatten()\n\n    intersection = (pred * target).sum()\n    dice = (2. * intersection + 1e-6) / (pred.sum() + target.sum() + 1e-6)  # Adding epsilon to avoid division by 0\n\n    return dice.item()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def display_segmentation_examples(inputs, masks, outputs, num_examples=3):\n    fig, axes = plt.subplots(num_examples, 3, figsize=(12, 4 * num_examples))\n    for i in range(num_examples):\n        ax = axes[i]\n        \n        # Original image\n        ax[0].imshow(inputs[i].cpu().numpy().transpose(1, 2, 0))  # Convert to HWC format\n        ax[0].set_title(\"Input Image\")\n        ax[0].axis('off')\n        \n        # Ground truth mask\n        ax[1].imshow(masks[i].cpu().numpy(), cmap='gray')\n        ax[1].set_title(\"Ground Truth\")\n        ax[1].axis('off')\n        \n        # Predicted mask\n        pred_mask = torch.argmax(outputs[i], dim=0)  # Take the class with the highest probability\n        ax[2].imshow(pred_mask.cpu().numpy(), cmap='gray')\n        ax[2].set_title(\"Prediction\")\n        ax[2].axis('off')\n    \n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate_model(val_loader, model, device):\n    model.eval()  # Set the model to evaluation mode\n    dice_scores = []\n\n    with torch.no_grad():\n        for i,(inputs, masks) in enumerate(val_loader):\n            if i > 20:\n                break\n                \n            inputs, masks = inputs.to(device), masks.to(device)\n\n            # Forward pass\n            outputs = model(inputs)['out']\n\n            # Resize the output to match the mask size (if needed)\n            outputs = torch.nn.functional.interpolate(outputs, size=masks.shape[1:], mode='bilinear', align_corners=False)\n\n            # Calculate the Dice score\n            pred_mask = torch.argmax(outputs, dim=1)  # Get the predicted mask\n            dice = dice_score(pred_mask, masks)\n            dice_scores.append(dice)\n\n            # Display segmentation examples for the first batch\n            display_segmentation_examples(inputs, masks, outputs, num_examples=1)\n\n    # Calculate the average Dice score\n    avg_dice_score = np.mean(dice_scores)\n    print(f\"Average Dice Score: {avg_dice_score:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"evaluate_model(val_loader, model, device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"from IPython.display import FileLink\nFileLink(r'best_model.pth')","metadata":{"execution":{"iopub.status.busy":"2024-12-06T19:27:32.879533Z","iopub.execute_input":"2024-12-06T19:27:32.879913Z","iopub.status.idle":"2024-12-06T19:27:32.886062Z","shell.execute_reply.started":"2024-12-06T19:27:32.879878Z","shell.execute_reply":"2024-12-06T19:27:32.885044Z"}}},{"cell_type":"code","source":"from IPython.display import FileLink\ns = FileLink(r'best_model.pth')\ns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T19:34:07.063048Z","iopub.execute_input":"2024-12-06T19:34:07.063489Z","iopub.status.idle":"2024-12-06T19:34:07.071169Z","shell.execute_reply.started":"2024-12-06T19:34:07.063450Z","shell.execute_reply":"2024-12-06T19:34:07.070242Z"}},"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/best_model.pth","text/html":"<a href='best_model.pth' target='_blank'>best_model.pth</a><br>"},"metadata":{}}],"execution_count":46},{"cell_type":"code","source":"https://kkb-production.jupyter-proxy.kaggle.net/k/211600123/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2IiwidHlwIjoiSldUIn0..aqvPDq8Wh3lpDru-0CaxOw.ap9Om70Vv_uU1PdJlz4IOl6f1yKZnM40tRpqT0Dt0f-1wiZilgU820wSOp0bkGY4br6Yd1U-rZSsT7xpdOR1oySmnbEaD_O0Rd1VPFFJDQgWt-6_ktcCEAWCei5GQV-DdkjgDcCvRt0XCP3P6_8_DnKmg-kxFohdqCQBCNkr5RR2t5FaYwuD1UWz6XqT5NbbbX0PJGqpExcq-GM7Ydw6-ANlwO5STu2GwKUeRVm4YlP0bwqAkspuJ6s2ukH5zo64.jCoSGdxH85Lqp2wRPNFg_g/proxy/files/best_model.pth","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T19:29:26.424779Z","iopub.execute_input":"2024-12-06T19:29:26.425129Z","iopub.status.idle":"2024-12-06T19:29:26.432250Z","shell.execute_reply.started":"2024-12-06T19:29:26.425096Z","shell.execute_reply":"2024-12-06T19:29:26.431243Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}